{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c64a3295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version: 2.11.0.dev20260211+cu130\n",
      "CUDA Available: True\n",
      "Device Name: NVIDIA GeForce RTX 5060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1. Î≤ÑÏ†Ñ ÌôïÏù∏\n",
    "print(f\"Torch Version: {torch.__version__}\")\n",
    "\n",
    "# 2. GPU Ïù∏Ïãù Ïó¨Î∂Ä (TrueÍ∞Ä ÎÇòÏôÄÏïº ÏÑ±Í≥µ)\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# 3. GPU Ïù¥Î¶Ñ Ï∂úÎ†•\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device Name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb096ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0212 17:44:19.486000 12032 site-packages\\torch\\utils\\flop_counter.py:29] triton not found; flop counting will not work for triton kernels\n",
      "c:\\Users\\kyle0\\miniconda3\\envs\\my_env\\lib\\site-packages\\pytorch_forecasting\\models\\base\\_base_model.py:30: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer, Baseline, QuantileLoss\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2a48d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store ID</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Region</th>\n",
       "      <th>Inventory Level</th>\n",
       "      <th>Units Sold</th>\n",
       "      <th>Units Ordered</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Weather Condition</th>\n",
       "      <th>Promotion</th>\n",
       "      <th>Competitor Pricing</th>\n",
       "      <th>Seasonality</th>\n",
       "      <th>Epidemic</th>\n",
       "      <th>Demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>S001</td>\n",
       "      <td>P0001</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>North</td>\n",
       "      <td>195</td>\n",
       "      <td>102</td>\n",
       "      <td>252</td>\n",
       "      <td>72.72</td>\n",
       "      <td>5</td>\n",
       "      <td>Snowy</td>\n",
       "      <td>0</td>\n",
       "      <td>85.73</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>S001</td>\n",
       "      <td>P0002</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>North</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>249</td>\n",
       "      <td>80.16</td>\n",
       "      <td>15</td>\n",
       "      <td>Snowy</td>\n",
       "      <td>1</td>\n",
       "      <td>92.02</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>S001</td>\n",
       "      <td>P0003</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>North</td>\n",
       "      <td>247</td>\n",
       "      <td>114</td>\n",
       "      <td>612</td>\n",
       "      <td>62.94</td>\n",
       "      <td>10</td>\n",
       "      <td>Snowy</td>\n",
       "      <td>1</td>\n",
       "      <td>60.08</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>S001</td>\n",
       "      <td>P0004</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>North</td>\n",
       "      <td>139</td>\n",
       "      <td>45</td>\n",
       "      <td>102</td>\n",
       "      <td>87.63</td>\n",
       "      <td>10</td>\n",
       "      <td>Snowy</td>\n",
       "      <td>0</td>\n",
       "      <td>85.19</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>S001</td>\n",
       "      <td>P0005</td>\n",
       "      <td>Groceries</td>\n",
       "      <td>North</td>\n",
       "      <td>152</td>\n",
       "      <td>65</td>\n",
       "      <td>271</td>\n",
       "      <td>54.41</td>\n",
       "      <td>0</td>\n",
       "      <td>Snowy</td>\n",
       "      <td>0</td>\n",
       "      <td>51.63</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Store ID Product ID     Category Region  Inventory Level  \\\n",
       "0  2022-01-01     S001      P0001  Electronics  North              195   \n",
       "1  2022-01-01     S001      P0002     Clothing  North              117   \n",
       "2  2022-01-01     S001      P0003     Clothing  North              247   \n",
       "3  2022-01-01     S001      P0004  Electronics  North              139   \n",
       "4  2022-01-01     S001      P0005    Groceries  North              152   \n",
       "\n",
       "   Units Sold  Units Ordered  Price  Discount Weather Condition  Promotion  \\\n",
       "0         102            252  72.72         5             Snowy          0   \n",
       "1         117            249  80.16        15             Snowy          1   \n",
       "2         114            612  62.94        10             Snowy          1   \n",
       "3          45            102  87.63        10             Snowy          0   \n",
       "4          65            271  54.41         0             Snowy          0   \n",
       "\n",
       "   Competitor Pricing Seasonality  Epidemic  Demand  \n",
       "0               85.73      Winter         0     115  \n",
       "1               92.02      Winter         0     229  \n",
       "2               60.08      Winter         0     157  \n",
       "3               85.19      Winter         0      52  \n",
       "4               51.63      Winter         0      59  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('sales_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54fa3606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFT data preprocessing completed\n",
      "========================================\n",
      "  Store ID       Date  time_idx    Demand\n",
      "0     S001 2022-01-01         0  4.753590\n",
      "1     S001 2022-01-02         1  4.442651\n",
      "2     S001 2022-01-03         2  4.890349\n",
      "3     S001 2022-01-04         3  4.219508\n",
      "4     S001 2022-01-05         4  4.709530\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()\n",
    "\n",
    "# Change 'Date' to datetime and sort by Store ID, Product ID, and Date\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.sort_values(['Store ID', 'Product ID', 'Date']).reset_index(drop=True)\n",
    "\n",
    "# Create time index for TFT\n",
    "df['time_idx'] = (df['Date'] - df['Date'].min()).dt.days\n",
    "\n",
    "# Convert categorical variables to string type for TFT\n",
    "categorical_cols = ['Store ID', 'Product ID', 'Category', 'Region', 'Weather Condition', 'Seasonality']\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].astype(str)\n",
    "\n",
    "# Extract date features\n",
    "df['Month'] = df['Date'].dt.month.astype(str)\n",
    "df['DayOfWeek'] = df['Date'].dt.dayofweek.astype(str)\n",
    "\n",
    "# Log-transform the target variable, inventory level and units ordered\n",
    "df['Demand'] = np.log1p(df['Demand'])\n",
    "df['Inventory Level'] = np.log1p(df['Inventory Level']) \n",
    "df['Units Ordered'] = np.log1p(df['Units Ordered'])\n",
    "\n",
    "# Drop 'Units Sold' to avoid data leakage      \n",
    "if 'Units Sold' in df.columns:\n",
    "    df.drop(columns=['Units Sold'], inplace=True)\n",
    "\n",
    "print(\"TFT data preprocessing completed\")\n",
    "print(\"========================================\")\n",
    "print(df[['Store ID', 'Date', 'time_idx', 'Demand']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dabec3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prediction_length = 30\n",
    "max_encoder_length = 90\n",
    "training_cutoff = df['time_idx'].max() - max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    df[df.time_idx <= training_cutoff],\n",
    "\n",
    "    time_idx='time_idx',\n",
    "    target='Demand',\n",
    "    \n",
    "    group_ids=['Store ID', 'Product ID'],\n",
    "\n",
    "    min_encoder_length=max_encoder_length // 2,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "\n",
    "    static_categoricals=[\"Store ID\", \"Product ID\", \"Category\", \"Region\"],\n",
    "\n",
    "    time_varying_known_categoricals=[\"Month\", \"DayOfWeek\", \"Seasonality\"],\n",
    "    time_varying_known_reals=[\"time_idx\", \"Price\", \"Promotion\", \"Discount\", \"Competitor Pricing\"],\n",
    "\n",
    "    time_varying_unknown_categoricals=[\"Weather Condition\"],\n",
    "    time_varying_unknown_reals=[\"Demand\", \"Inventory Level\", \"Epidemic\"],\n",
    "\n",
    "    target_normalizer=GroupNormalizer(groups=[\"Store ID\", \"Product ID\"], transformation=\"softplus\"),\n",
    "\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    allow_missing_timesteps=True\n",
    ")\n",
    "\n",
    "validation = TimeSeriesDataSet.from_dataset(training, df, predict=True, stop_randomization=True)\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6458a5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "c:\\Users\\kyle0\\miniconda3\\envs\\my_env\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:213: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "c:\\Users\\kyle0\\miniconda3\\envs\\my_env\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:213: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "üí° Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Î™®Îç∏ ÌååÎùºÎØ∏ÌÑ∞ Ïàò: 92.5k\n",
      "üöÄ Start TFT Learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                               | Type                            | Params | Mode  | FLOPs\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train | 0    \n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train | 0    \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 363    | train | 0    \n",
      "3  | prescalers                         | ModuleDict                      | 384    | train | 0    \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 6.5 K  | train | 0    \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 19.9 K | train | 0    \n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 12.8 K | train | 0    \n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train | 0    \n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train | 0    \n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train | 0    \n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train | 0    \n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train | 0    \n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train | 0    \n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train | 0    \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train | 0    \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train | 0    \n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 2.6 K  | train | 0    \n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train | 0    \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train | 0    \n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train | 0    \n",
      "20 | output_layer                       | Linear                          | 231    | train | 0    \n",
      "--------------------------------------------------------------------------------------------------------\n",
      "92.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "92.5 K    Total params\n",
      "0.370     Total estimated model params size (MB)\n",
      "477       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kyle0\\miniconda3\\envs\\my_env\\lib\\site-packages\\lightning\\pytorch\\utilities\\_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.\n",
      "c:\\Users\\kyle0\\miniconda3\\envs\\my_env\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:429: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kyle0\\miniconda3\\envs\\my_env\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:429: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1185/1185 [02:37<00:00,  7.50it/s, v_num=0, train_loss_step=0.0364, val_loss=0.0453, train_loss_epoch=0.0348]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1185/1185 [02:38<00:00,  7.50it/s, v_num=0, train_loss_step=0.0364, val_loss=0.0453, train_loss_epoch=0.0348]\n",
      "‚úÖ Learning Complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kyle0\\miniconda3\\envs\\my_env\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:213: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "c:\\Users\\kyle0\\miniconda3\\envs\\my_env\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:213: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42)\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=32,           \n",
    "    attention_head_size=4,    \n",
    "    dropout=0.1,              \n",
    "    hidden_continuous_size=16,\n",
    "    output_size=7,            \n",
    "    loss=QuantileLoss(),      \n",
    "    log_interval=10, \n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "print(f\"Î™®Îç∏ ÌååÎùºÎØ∏ÌÑ∞ Ïàò: {tft.size()/1e3:.1f}k\")\n",
    "\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"tft_demand_forecasting\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    gradient_clip_val=0.1, \n",
    "    logger=logger,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\"),\n",
    "        LearningRateMonitor()\n",
    "    ],\n",
    "    enable_model_summary=True,\n",
    ")\n",
    "\n",
    "print(\"üöÄ Start TFT Learning...\")\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")\n",
    "print(\"‚úÖ Learning Complete!\")\n",
    "\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c48ad7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 1).\n",
       "Contents of stderr:\n",
       "Traceback (most recent call last):\n",
       "  File \"C:\\Users\\kyle0\\miniconda3\\envs\\my_env\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
       "    return _run_code(code, main_globals, None,\n",
       "  File \"C:\\Users\\kyle0\\miniconda3\\envs\\my_env\\lib\\runpy.py\", line 86, in _run_code\n",
       "    exec(code, run_globals)\n",
       "  File \"C:\\Users\\kyle0\\miniconda3\\envs\\my_env\\Scripts\\tensorboard.exe\\__main__.py\", line 2, in <module>\n",
       "  File \"C:\\Users\\kyle0\\miniconda3\\envs\\my_env\\lib\\site-packages\\tensorboard\\main.py\", line 27, in <module>\n",
       "    from tensorboard import default\n",
       "  File \"C:\\Users\\kyle0\\miniconda3\\envs\\my_env\\lib\\site-packages\\tensorboard\\default.py\", line 30, in <module>\n",
       "    import pkg_resources\n",
       "ModuleNotFoundError: No module named 'pkg_resources'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ÌÖêÏÑúÎ≥¥Îìú ÌôïÏû• ÌîÑÎ°úÍ∑∏Îû® Î°úÎìú\n",
    "%load_ext tensorboard\n",
    "\n",
    "# ÌÖêÏÑúÎ≥¥Îìú Ïã§Ìñâ (Î°úÍ∑∏ ÎîîÎ†âÌÜ†Î¶¨ ÏßÄÏ†ï)\n",
    "%tensorboard --logdir lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7bb94a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "plot_prediction requires matplotlib. Please install matplotlib with `pip install matplotlib`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m): \n\u001b[0;32m     29\u001b[0m     fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m---> 30\u001b[0m     \u001b[43mbest_tft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_loss_to_title\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43max\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample Prediction \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\kyle0\\miniconda3\\envs\\my_env\\lib\\site-packages\\pytorch_forecasting\\models\\temporal_fusion_transformer\\_tft.py:893\u001b[0m, in \u001b[0;36mTemporalFusionTransformer.plot_prediction\u001b[1;34m(self, x, out, idx, plot_attention, add_loss_to_title, show_future_observed, ax, **kwargs)\u001b[0m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;124;03mPlot actuals vs prediction and attention\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;124;03m    plt.Figure: matplotlib figure\u001b[39;00m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    892\u001b[0m \u001b[38;5;66;03m# plot prediction as normal\u001b[39;00m\n\u001b[1;32m--> 893\u001b[0m fig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mplot_prediction(\n\u001b[0;32m    894\u001b[0m     x,\n\u001b[0;32m    895\u001b[0m     out,\n\u001b[0;32m    896\u001b[0m     idx\u001b[38;5;241m=\u001b[39midx,\n\u001b[0;32m    897\u001b[0m     add_loss_to_title\u001b[38;5;241m=\u001b[39madd_loss_to_title,\n\u001b[0;32m    898\u001b[0m     show_future_observed\u001b[38;5;241m=\u001b[39mshow_future_observed,\n\u001b[0;32m    899\u001b[0m     ax\u001b[38;5;241m=\u001b[39max,\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    901\u001b[0m )\n\u001b[0;32m    903\u001b[0m \u001b[38;5;66;03m# add attention on secondary axis\u001b[39;00m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m plot_attention:\n",
      "File \u001b[1;32mc:\\Users\\kyle0\\miniconda3\\envs\\my_env\\lib\\site-packages\\pytorch_forecasting\\models\\base\\_base_model.py:1197\u001b[0m, in \u001b[0;36mBaseModel.plot_prediction\u001b[1;34m(self, x, out, idx, add_loss_to_title, show_future_observed, ax, quantiles_kwargs, prediction_kwargs)\u001b[0m\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1195\u001b[0m     prediction_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1197\u001b[0m \u001b[43m_check_matplotlib\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplot_prediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1199\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;66;03m# all true values for y of the first sample in batch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kyle0\\miniconda3\\envs\\my_env\\lib\\site-packages\\pytorch_forecasting\\utils\\_dependencies\\_dependencies.py:27\u001b[0m, in \u001b[0;36m_check_matplotlib\u001b[1;34m(ref, raise_error)\u001b[0m\n\u001b[0;32m     25\u001b[0m matplotlib_present \u001b[38;5;241m=\u001b[39m _check_soft_dependencies(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m\"\u001b[39m, severity\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_error \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m matplotlib_present:\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires matplotlib.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please install matplotlib with `pip install matplotlib`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m     )\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m matplotlib_present\n",
      "\u001b[1;31mImportError\u001b[0m: plot_prediction requires matplotlib. Please install matplotlib with `pip install matplotlib`."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# 4. ÏòàÏ∏° Î∞è ÏãúÍ∞ÅÌôî (Prediction & Visualization)\n",
    "# ====================================================\n",
    "\n",
    "# Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌïú ÏòàÏ∏° ÏàòÌñâ\n",
    "# mode=\"prediction\" (Ï†ê Ï∂îÏ†ï), mode=\"quantiles\" (Íµ¨Í∞Ñ Ï∂îÏ†ï), mode=\"raw\" (Ï†ÑÏ≤¥)\n",
    "predictions = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True)\n",
    "\n",
    "# ÏòàÏ∏°Í∞í Ï∂îÏ∂ú (Î°úÍ∑∏ Ïä§ÏºÄÏùº -> Ïã§Ï†ú Ïä§ÏºÄÏùº Î≥ÄÌôò)\n",
    "# output.predictionÏùÄ Í∏∞Î≥∏Ï†ÅÏúºÎ°ú Median(0.5 quantile) ÌòπÏùÄ MeanÏùÑ Î∞òÌôò\n",
    "pred_raw = predictions.output\n",
    "pred_median = np.expm1(pred_raw.prediction.cpu().numpy()) \n",
    "\n",
    "# Ïã†Î¢∞Íµ¨Í∞Ñ Ï∂îÏ∂ú (Quantiles)\n",
    "# output_size=7Ïùº Îïå, Ïù∏Îç±Ïä§: 0(0.02), 1(0.1), 2(0.25), 3(0.5), 4(0.75), 5(0.9), 6(0.98)\n",
    "# 95% Ïã†Î¢∞Íµ¨Í∞Ñ = ÌïòÏúÑ 2.5%(Ïù∏Îç±Ïä§ 0 Í∑ºÏÇ¨) ~ ÏÉÅÏúÑ 97.5%(Ïù∏Îç±Ïä§ 6 Í∑ºÏÇ¨)\n",
    "pred_lower = np.expm1(pred_raw.prediction[:, :, 0].cpu().numpy()) \n",
    "pred_upper = np.expm1(pred_raw.prediction[:, :, 6].cpu().numpy())\n",
    "\n",
    "# Ïã§Ï†úÍ∞í Ï∂îÏ∂ú (Ï≤´ Î≤àÏß∏ ÌÉÄÏûÑÏä§ÌÖùÏùò Ïã§Ï†úÍ∞í)\n",
    "# Ï£ºÏùò: TFTÏùò dataloaderÎäî ÏúàÎèÑÏö∞ Î∞©ÏãùÏúºÎ°ú Îç∞Ïù¥ÌÑ∞Î•º Î±âÏúºÎØÄÎ°ú Ïã§Ï†úÍ∞í Ï†ïÎ†¨Ïóê Ï£ºÏùòÌï¥Ïïº Ìï®\n",
    "actuals = np.expm1(torch.cat([y[0] for x, y in iter(val_dataloader)]).cpu().numpy())\n",
    "\n",
    "# --- Í≤∞Í≥º ÏãúÍ∞ÅÌôî (Sample Plot) ---\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TFT ÎÇ¥Ïû• ÌîåÎ°úÌåÖ Í∏∞Îä• ÏÇ¨Ïö© (ÎûúÎç§ ÏÉòÌîå 3Í∞ú)\n",
    "for idx in range(3): \n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    best_tft.plot_prediction(predictions.x, predictions.output, idx=idx, add_loss_to_title=True, ax=ax)\n",
    "    plt.title(f\"Sample Prediction {idx+1}\")\n",
    "    plt.show()\n",
    "\n",
    "# --- Î≥ÄÏàò Ï§ëÏöîÎèÑ (Interpretation) ---\n",
    "# TFTÏùò Í∞ïÎ†•Ìïú Ïû•Ï†ê: Ìï¥ÏÑùÎ†•\n",
    "interpretation = best_tft.interpret_output(predictions.output, reduction=\"sum\")\n",
    "best_tft.plot_interpretation(interpretation)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
